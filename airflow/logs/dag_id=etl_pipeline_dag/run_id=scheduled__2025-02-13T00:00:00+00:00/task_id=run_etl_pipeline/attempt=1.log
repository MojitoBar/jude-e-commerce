[2025-02-14T05:50:24.365+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-14T05:50:24.375+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [queued]>
[2025-02-14T05:50:24.379+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [queued]>
[2025-02-14T05:50:24.379+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-14T05:50:24.392+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): run_etl_pipeline> on 2025-02-13 00:00:00+00:00
[2025-02-14T05:50:24.400+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=220) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-02-14T05:50:24.401+0000] {standard_task_runner.py:72} INFO - Started process 222 to run task
[2025-02-14T05:50:24.400+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'etl_pipeline_dag', 'run_etl_pipeline', 'scheduled__2025-02-13T00:00:00+00:00', '--job-id', '41', '--raw', '--subdir', 'DAGS_FOLDER/etl_pipeline_dag.py', '--cfg-path', '/tmp/tmp3wnup0bw']
[2025-02-14T05:50:24.402+0000] {standard_task_runner.py:105} INFO - Job 41: Subtask run_etl_pipeline
[2025-02-14T05:50:24.428+0000] {task_command.py:467} INFO - Running <TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [running]> on host 5bdf8fbd2eb2
[2025-02-14T05:50:24.467+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='etl_pipeline_dag' AIRFLOW_CTX_TASK_ID='run_etl_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-02-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-13T00:00:00+00:00'
[2025-02-14T05:50:24.468+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-14T05:50:24.487+0000] {logging_mixin.py:190} INFO - Starting ETL pipeline...
[2025-02-14T05:50:24.487+0000] {logging_mixin.py:190} INFO - Extracting data...
[2025-02-14T05:50:24.491+0000] {logging_mixin.py:190} INFO - ETL pipeline failed: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "postgres"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-02-14T05:50:24.492+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-02-14T05:50:24.495+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-14T05:50:24.496+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=etl_pipeline_dag, task_id=run_etl_pipeline, run_id=scheduled__2025-02-13T00:00:00+00:00, execution_date=20250213T000000, start_date=20250214T055024, end_date=20250214T055024
[2025-02-14T05:50:24.542+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-02-14T05:50:24.551+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-14T05:50:24.552+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-14T05:52:47.225+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-14T05:52:47.248+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [queued]>
[2025-02-14T05:52:47.259+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [queued]>
[2025-02-14T05:52:47.260+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-14T05:52:47.385+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): run_etl_pipeline> on 2025-02-13 00:00:00+00:00
[2025-02-14T05:52:47.404+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'etl_pipeline_dag', 'run_etl_pipeline', 'scheduled__2025-02-13T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/etl_pipeline_dag.py', '--cfg-path', '/tmp/tmprf8l00qu']
[2025-02-14T05:52:47.407+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=217) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-02-14T05:52:47.407+0000] {standard_task_runner.py:105} INFO - Job 2: Subtask run_etl_pipeline
[2025-02-14T05:52:47.408+0000] {standard_task_runner.py:72} INFO - Started process 219 to run task
[2025-02-14T05:52:47.488+0000] {task_command.py:467} INFO - Running <TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [running]> on host f5fadfece92c
[2025-02-14T05:52:47.759+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='etl_pipeline_dag' AIRFLOW_CTX_TASK_ID='run_etl_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-02-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-13T00:00:00+00:00'
[2025-02-14T05:52:47.761+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-14T05:52:47.893+0000] {logging_mixin.py:190} INFO - Starting ETL pipeline...
[2025-02-14T05:52:47.899+0000] {logging_mixin.py:190} INFO - Extracting data...
[2025-02-14T05:52:47.906+0000] {logging_mixin.py:190} INFO - ETL pipeline failed: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "postgres"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-02-14T05:52:47.906+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-02-14T05:52:47.909+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-14T05:52:47.910+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=etl_pipeline_dag, task_id=run_etl_pipeline, run_id=scheduled__2025-02-13T00:00:00+00:00, execution_date=20250213T000000, start_date=20250214T055247, end_date=20250214T055247
[2025-02-14T05:52:47.930+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-02-14T05:52:47.939+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-14T05:52:47.940+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-14T06:08:27.389+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-14T06:08:27.396+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [queued]>
[2025-02-14T06:08:27.401+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [queued]>
[2025-02-14T06:08:27.402+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-14T06:08:27.409+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): run_etl_pipeline> on 2025-02-13 00:00:00+00:00
[2025-02-14T06:08:27.417+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'etl_pipeline_dag', 'run_etl_pipeline', 'scheduled__2025-02-13T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/etl_pipeline_dag.py', '--cfg-path', '/tmp/tmpk4or1x3w']
[2025-02-14T06:08:27.419+0000] {standard_task_runner.py:105} INFO - Job 2: Subtask run_etl_pipeline
[2025-02-14T06:08:27.419+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=260) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-02-14T06:08:27.419+0000] {standard_task_runner.py:72} INFO - Started process 261 to run task
[2025-02-14T06:08:27.443+0000] {task_command.py:467} INFO - Running <TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [running]> on host 774b503fbcb2
[2025-02-14T06:08:27.482+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='etl_pipeline_dag' AIRFLOW_CTX_TASK_ID='run_etl_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-02-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-13T00:00:00+00:00'
[2025-02-14T06:08:27.482+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-14T06:08:27.509+0000] {logging_mixin.py:190} INFO - Starting ETL pipeline...
[2025-02-14T06:08:27.510+0000] {logging_mixin.py:190} INFO - Extracting data...
[2025-02-14T06:08:27.512+0000] {logging_mixin.py:190} INFO - Data extraction failed: [Errno 2] No such file or directory: '/opt/***/data/data.csv'
[2025-02-14T06:08:27.512+0000] {logging_mixin.py:190} INFO - ETL pipeline failed: [Errno 2] No such file or directory: '/opt/***/data/data.csv'
[2025-02-14T06:08:27.512+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/scripts/etl_pipeline.py", line 87, in run_etl_script
    raw_data = extract_data()
               ^^^^^^^^^^^^^^
  File "/opt/airflow/scripts/etl_pipeline.py", line 11, in extract_data
    df = pd.read_csv('/opt/airflow/data/data.csv')
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/data.csv'
[2025-02-14T06:08:27.520+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=etl_pipeline_dag, task_id=run_etl_pipeline, run_id=scheduled__2025-02-13T00:00:00+00:00, execution_date=20250213T000000, start_date=20250214T060827, end_date=20250214T060827
[2025-02-14T06:08:27.535+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-14T06:08:27.536+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 2 for task run_etl_pipeline ([Errno 2] No such file or directory: '/opt/airflow/data/data.csv'; 261)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/scripts/etl_pipeline.py", line 87, in run_etl_script
    raw_data = extract_data()
               ^^^^^^^^^^^^^^
  File "/opt/airflow/scripts/etl_pipeline.py", line 11, in extract_data
    df = pd.read_csv('/opt/airflow/data/data.csv')
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/data.csv'
[2025-02-14T06:08:27.563+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-02-14T06:08:27.584+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-14T06:08:27.586+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-14T06:26:44.429+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-14T06:26:44.522+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [queued]>
[2025-02-14T06:26:44.558+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [queued]>
[2025-02-14T06:26:44.561+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-14T06:26:44.585+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): run_etl_pipeline> on 2025-02-13 00:00:00+00:00
[2025-02-14T06:26:44.608+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'etl_pipeline_dag', 'run_etl_pipeline', 'scheduled__2025-02-13T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/etl_pipeline_dag.py', '--cfg-path', '/tmp/tmplnw7i284']
[2025-02-14T06:26:44.616+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask run_etl_pipeline
[2025-02-14T06:26:44.617+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=209) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-02-14T06:26:44.620+0000] {standard_task_runner.py:72} INFO - Started process 213 to run task
[2025-02-14T06:26:44.756+0000] {task_command.py:467} INFO - Running <TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [running]> on host eb31e5c80e52
[2025-02-14T06:26:44.972+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='etl_pipeline_dag' AIRFLOW_CTX_TASK_ID='run_etl_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-02-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-13T00:00:00+00:00'
[2025-02-14T06:26:44.976+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-14T06:26:45.071+0000] {logging_mixin.py:190} INFO - Starting ETL pipeline...
[2025-02-14T06:26:45.072+0000] {logging_mixin.py:190} INFO - Extracting data...
[2025-02-14T06:29:43.067+0000] {logging_mixin.py:190} INFO - Detected file encoding: ISO-8859-1
[2025-02-14T06:29:43.618+0000] {logging_mixin.py:190} INFO - CSV 파일 컬럼: ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
[2025-02-14T06:29:43.621+0000] {logging_mixin.py:190} INFO - 데이터 샘플:
[2025-02-14T06:29:43.648+0000] {logging_mixin.py:190} INFO -    InvoiceNo StockCode  ... CustomerID         Country
0    536365    85123A  ...    17850.0  United Kingdom
1    536365     71053  ...    17850.0  United Kingdom
2    536365    84406B  ...    17850.0  United Kingdom
3    536365    84029G  ...    17850.0  United Kingdom
4    536365    84029E  ...    17850.0  United Kingdom

[5 rows x 8 columns]
[2025-02-14T06:29:43.648+0000] {logging_mixin.py:190} INFO - Data extracted successfully!
[2025-02-14T06:29:43.648+0000] {logging_mixin.py:190} INFO - Transforming data...
[2025-02-14T06:29:43.648+0000] {logging_mixin.py:190} INFO - 변환 전 컬럼: ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
[2025-02-14T06:29:43.928+0000] {logging_mixin.py:190} INFO - Data transformed successfully!
[2025-02-14T06:29:43.929+0000] {logging_mixin.py:190} INFO - Loading data...
[2025-02-14T06:29:51.415+0000] {logging_mixin.py:190} INFO - Data loading failed: (psycopg2.errors.UndefinedColumn) column "Country" of relation "sales" does not exist
LINE 1: ...product_name, quantity, date, price, customer_id, "Country",...
                                                             ^

[SQL: INSERT INTO sales (invoice_no, stock_code, product_name, quantity, date, price, customer_id, "Country", total_amount) VALUES (%(invoice_no)s, %(stock_code)s, %(product_name)s, %(quantity)s, %(date)s, %(price)s, %(customer_id)s, %(Country)s, %(total_amount)s)]
[parameters: ({'invoice_no': '536365', 'stock_code': '85123A', 'product_name': 'WHITE HANGING HEART T-LIGHT HOLDER', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 2.55, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 15.299999999999999}, {'invoice_no': '536365', 'stock_code': '71053', 'product_name': 'WHITE METAL LANTERN', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '84406B', 'product_name': 'CREAM CUPID HEARTS COAT HANGER', 'quantity': 8, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 2.75, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 22.0}, {'invoice_no': '536365', 'stock_code': '84029G', 'product_name': 'KNITTED UNION FLAG HOT WATER BOTTLE', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '84029E', 'product_name': 'RED WOOLLY HOTTIE WHITE HEART.', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '22752', 'product_name': 'SET 7 BABUSHKA NESTING BOXES', 'quantity': 2, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 7.65, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 15.3}, {'invoice_no': '536365', 'stock_code': '21730', 'product_name': 'GLASS STAR FROSTED T-LIGHT HOLDER', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 4.25, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 25.5}, {'invoice_no': '536366', 'stock_code': '22633', 'product_name': 'HAND WARMER UNION JACK', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 28), 'price': 1.85, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 11.100000000000001}  ... displaying 10 of 541909 total bound parameter sets ...  {'invoice_no': '581587', 'stock_code': '23255', 'product_name': 'CHILDRENS CUTLERY CIRCUS PARADE', 'quantity': 4, 'date': datetime.datetime(2011, 12, 9, 12, 50), 'price': 4.15, 'customer_id': 12680.0, 'Country': 'France', 'total_amount': 16.6}, {'invoice_no': '581587', 'stock_code': '22138', 'product_name': 'BAKING SET 9 PIECE RETROSPOT ', 'quantity': 3, 'date': datetime.datetime(2011, 12, 9, 12, 50), 'price': 4.95, 'customer_id': 12680.0, 'Country': 'France', 'total_amount': 14.850000000000001})]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2025-02-14T06:29:51.417+0000] {logging_mixin.py:190} INFO - ETL pipeline failed: (psycopg2.errors.UndefinedColumn) column "Country" of relation "sales" does not exist
LINE 1: ...product_name, quantity, date, price, customer_id, "Country",...
                                                             ^

[SQL: INSERT INTO sales (invoice_no, stock_code, product_name, quantity, date, price, customer_id, "Country", total_amount) VALUES (%(invoice_no)s, %(stock_code)s, %(product_name)s, %(quantity)s, %(date)s, %(price)s, %(customer_id)s, %(Country)s, %(total_amount)s)]
[parameters: ({'invoice_no': '536365', 'stock_code': '85123A', 'product_name': 'WHITE HANGING HEART T-LIGHT HOLDER', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 2.55, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 15.299999999999999}, {'invoice_no': '536365', 'stock_code': '71053', 'product_name': 'WHITE METAL LANTERN', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '84406B', 'product_name': 'CREAM CUPID HEARTS COAT HANGER', 'quantity': 8, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 2.75, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 22.0}, {'invoice_no': '536365', 'stock_code': '84029G', 'product_name': 'KNITTED UNION FLAG HOT WATER BOTTLE', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '84029E', 'product_name': 'RED WOOLLY HOTTIE WHITE HEART.', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '22752', 'product_name': 'SET 7 BABUSHKA NESTING BOXES', 'quantity': 2, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 7.65, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 15.3}, {'invoice_no': '536365', 'stock_code': '21730', 'product_name': 'GLASS STAR FROSTED T-LIGHT HOLDER', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 4.25, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 25.5}, {'invoice_no': '536366', 'stock_code': '22633', 'product_name': 'HAND WARMER UNION JACK', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 28), 'price': 1.85, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 11.100000000000001}  ... displaying 10 of 541909 total bound parameter sets ...  {'invoice_no': '581587', 'stock_code': '23255', 'product_name': 'CHILDRENS CUTLERY CIRCUS PARADE', 'quantity': 4, 'date': datetime.datetime(2011, 12, 9, 12, 50), 'price': 4.15, 'customer_id': 12680.0, 'Country': 'France', 'total_amount': 16.6}, {'invoice_no': '581587', 'stock_code': '22138', 'product_name': 'BAKING SET 9 PIECE RETROSPOT ', 'quantity': 3, 'date': datetime.datetime(2011, 12, 9, 12, 50), 'price': 4.95, 'customer_id': 12680.0, 'Country': 'France', 'total_amount': 14.850000000000001})]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2025-02-14T06:29:51.417+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.UndefinedColumn: column "Country" of relation "sales" does not exist
LINE 1: ...product_name, quantity, date, price, customer_id, "Country",...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/scripts/etl_pipeline.py", line 124, in run_etl_script
    load_data(transformed_data, customer_summary, engine)
  File "/opt/airflow/scripts/etl_pipeline.py", line 98, in load_data
    df.to_sql('sales', engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "Country" of relation "sales" does not exist
LINE 1: ...product_name, quantity, date, price, customer_id, "Country",...
                                                             ^

[SQL: INSERT INTO sales (invoice_no, stock_code, product_name, quantity, date, price, customer_id, "Country", total_amount) VALUES (%(invoice_no)s, %(stock_code)s, %(product_name)s, %(quantity)s, %(date)s, %(price)s, %(customer_id)s, %(Country)s, %(total_amount)s)]
[parameters: ({'invoice_no': '536365', 'stock_code': '85123A', 'product_name': 'WHITE HANGING HEART T-LIGHT HOLDER', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 2.55, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 15.299999999999999}, {'invoice_no': '536365', 'stock_code': '71053', 'product_name': 'WHITE METAL LANTERN', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '84406B', 'product_name': 'CREAM CUPID HEARTS COAT HANGER', 'quantity': 8, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 2.75, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 22.0}, {'invoice_no': '536365', 'stock_code': '84029G', 'product_name': 'KNITTED UNION FLAG HOT WATER BOTTLE', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '84029E', 'product_name': 'RED WOOLLY HOTTIE WHITE HEART.', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '22752', 'product_name': 'SET 7 BABUSHKA NESTING BOXES', 'quantity': 2, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 7.65, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 15.3}, {'invoice_no': '536365', 'stock_code': '21730', 'product_name': 'GLASS STAR FROSTED T-LIGHT HOLDER', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 4.25, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 25.5}, {'invoice_no': '536366', 'stock_code': '22633', 'product_name': 'HAND WARMER UNION JACK', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 28), 'price': 1.85, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 11.100000000000001}  ... displaying 10 of 541909 total bound parameter sets ...  {'invoice_no': '581587', 'stock_code': '23255', 'product_name': 'CHILDRENS CUTLERY CIRCUS PARADE', 'quantity': 4, 'date': datetime.datetime(2011, 12, 9, 12, 50), 'price': 4.15, 'customer_id': 12680.0, 'Country': 'France', 'total_amount': 16.6}, {'invoice_no': '581587', 'stock_code': '22138', 'product_name': 'BAKING SET 9 PIECE RETROSPOT ', 'quantity': 3, 'date': datetime.datetime(2011, 12, 9, 12, 50), 'price': 4.95, 'customer_id': 12680.0, 'Country': 'France', 'total_amount': 14.850000000000001})]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2025-02-14T06:29:51.442+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=etl_pipeline_dag, task_id=run_etl_pipeline, run_id=scheduled__2025-02-13T00:00:00+00:00, execution_date=20250213T000000, start_date=20250214T062644, end_date=20250214T062951
[2025-02-14T06:29:51.474+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-14T06:29:51.474+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 3 for task run_etl_pipeline ((psycopg2.errors.UndefinedColumn) column "Country" of relation "sales" does not exist
LINE 1: ...product_name, quantity, date, price, customer_id, "Country",...
                                                             ^

[SQL: INSERT INTO sales (invoice_no, stock_code, product_name, quantity, date, price, customer_id, "Country", total_amount) VALUES (%(invoice_no)s, %(stock_code)s, %(product_name)s, %(quantity)s, %(date)s, %(price)s, %(customer_id)s, %(Country)s, %(total_amount)s)]
[parameters: ({'invoice_no': '536365', 'stock_code': '85123A', 'product_name': 'WHITE HANGING HEART T-LIGHT HOLDER', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 2.55, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 15.299999999999999}, {'invoice_no': '536365', 'stock_code': '71053', 'product_name': 'WHITE METAL LANTERN', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '84406B', 'product_name': 'CREAM CUPID HEARTS COAT HANGER', 'quantity': 8, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 2.75, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 22.0}, {'invoice_no': '536365', 'stock_code': '84029G', 'product_name': 'KNITTED UNION FLAG HOT WATER BOTTLE', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '84029E', 'product_name': 'RED WOOLLY HOTTIE WHITE HEART.', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '22752', 'product_name': 'SET 7 BABUSHKA NESTING BOXES', 'quantity': 2, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 7.65, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 15.3}, {'invoice_no': '536365', 'stock_code': '21730', 'product_name': 'GLASS STAR FROSTED T-LIGHT HOLDER', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 4.25, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 25.5}, {'invoice_no': '536366', 'stock_code': '22633', 'product_name': 'HAND WARMER UNION JACK', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 28), 'price': 1.85, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 11.100000000000001}  ... displaying 10 of 541909 total bound parameter sets ...  {'invoice_no': '581587', 'stock_code': '23255', 'product_name': 'CHILDRENS CUTLERY CIRCUS PARADE', 'quantity': 4, 'date': datetime.datetime(2011, 12, 9, 12, 50), 'price': 4.15, 'customer_id': 12680.0, 'Country': 'France', 'total_amount': 16.6}, {'invoice_no': '581587', 'stock_code': '22138', 'product_name': 'BAKING SET 9 PIECE RETROSPOT ', 'quantity': 3, 'date': datetime.datetime(2011, 12, 9, 12, 50), 'price': 4.95, 'customer_id': 12680.0, 'Country': 'France', 'total_amount': 14.850000000000001})]
(Background on this error at: https://sqlalche.me/e/14/f405); 213)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
psycopg2.errors.UndefinedColumn: column "Country" of relation "sales" does not exist
LINE 1: ...product_name, quantity, date, price, customer_id, "Country",...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/scripts/etl_pipeline.py", line 124, in run_etl_script
    load_data(transformed_data, customer_summary, engine)
  File "/opt/airflow/scripts/etl_pipeline.py", line 98, in load_data
    df.to_sql('sales', engine, if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1958, in to_sql
    total_inserted = sql_engine.insert_records(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1507, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1498, in insert_records
    return table.insert(chunksize=chunksize, method=method)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1059, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 951, in _execute_insert
    result = conn.execute(self.table.insert(), data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1890, in _execute_context
    self.dialect.do_executemany(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 982, in do_executemany
    context._psycopg2_fetched_rows = xtras.execute_values(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "Country" of relation "sales" does not exist
LINE 1: ...product_name, quantity, date, price, customer_id, "Country",...
                                                             ^

[SQL: INSERT INTO sales (invoice_no, stock_code, product_name, quantity, date, price, customer_id, "Country", total_amount) VALUES (%(invoice_no)s, %(stock_code)s, %(product_name)s, %(quantity)s, %(date)s, %(price)s, %(customer_id)s, %(Country)s, %(total_amount)s)]
[parameters: ({'invoice_no': '536365', 'stock_code': '85123A', 'product_name': 'WHITE HANGING HEART T-LIGHT HOLDER', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 2.55, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 15.299999999999999}, {'invoice_no': '536365', 'stock_code': '71053', 'product_name': 'WHITE METAL LANTERN', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '84406B', 'product_name': 'CREAM CUPID HEARTS COAT HANGER', 'quantity': 8, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 2.75, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 22.0}, {'invoice_no': '536365', 'stock_code': '84029G', 'product_name': 'KNITTED UNION FLAG HOT WATER BOTTLE', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '84029E', 'product_name': 'RED WOOLLY HOTTIE WHITE HEART.', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 3.39, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 20.34}, {'invoice_no': '536365', 'stock_code': '22752', 'product_name': 'SET 7 BABUSHKA NESTING BOXES', 'quantity': 2, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 7.65, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 15.3}, {'invoice_no': '536365', 'stock_code': '21730', 'product_name': 'GLASS STAR FROSTED T-LIGHT HOLDER', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 26), 'price': 4.25, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 25.5}, {'invoice_no': '536366', 'stock_code': '22633', 'product_name': 'HAND WARMER UNION JACK', 'quantity': 6, 'date': datetime.datetime(2010, 12, 1, 8, 28), 'price': 1.85, 'customer_id': 17850.0, 'Country': 'United Kingdom', 'total_amount': 11.100000000000001}  ... displaying 10 of 541909 total bound parameter sets ...  {'invoice_no': '581587', 'stock_code': '23255', 'product_name': 'CHILDRENS CUTLERY CIRCUS PARADE', 'quantity': 4, 'date': datetime.datetime(2011, 12, 9, 12, 50), 'price': 4.15, 'customer_id': 12680.0, 'Country': 'France', 'total_amount': 16.6}, {'invoice_no': '581587', 'stock_code': '22138', 'product_name': 'BAKING SET 9 PIECE RETROSPOT ', 'quantity': 3, 'date': datetime.datetime(2011, 12, 9, 12, 50), 'price': 4.95, 'customer_id': 12680.0, 'Country': 'France', 'total_amount': 14.850000000000001})]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2025-02-14T06:29:51.527+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-02-14T06:29:51.572+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-14T06:29:51.574+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-14T06:45:02.160+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-14T06:45:02.176+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [queued]>
[2025-02-14T06:45:02.185+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [queued]>
[2025-02-14T06:45:02.185+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-14T06:45:02.201+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): run_etl_pipeline> on 2025-02-13 00:00:00+00:00
[2025-02-14T06:45:02.212+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'etl_pipeline_dag', 'run_etl_pipeline', 'scheduled__2025-02-13T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/etl_pipeline_dag.py', '--cfg-path', '/tmp/tmpuufk2zwh']
[2025-02-14T06:45:02.215+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask run_etl_pipeline
[2025-02-14T06:45:02.215+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=206) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-02-14T06:45:02.217+0000] {standard_task_runner.py:72} INFO - Started process 210 to run task
[2025-02-14T06:45:02.272+0000] {task_command.py:467} INFO - Running <TaskInstance: etl_pipeline_dag.run_etl_pipeline scheduled__2025-02-13T00:00:00+00:00 [running]> on host f6fcc891b4f2
[2025-02-14T06:45:02.347+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='etl_pipeline_dag' AIRFLOW_CTX_TASK_ID='run_etl_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-02-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-13T00:00:00+00:00'
[2025-02-14T06:45:02.348+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-14T06:45:02.368+0000] {logging_mixin.py:190} INFO - Starting ETL pipeline...
[2025-02-14T06:45:02.369+0000] {logging_mixin.py:190} INFO - Extracting data...
[2025-02-14T06:45:02.369+0000] {logging_mixin.py:190} INFO - File can be opened for reading
[2025-02-14T06:47:08.608+0000] {logging_mixin.py:190} INFO - Detected file encoding: ISO-8859-1
[2025-02-14T06:47:09.112+0000] {logging_mixin.py:190} INFO - CSV 파일 컬럼: ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
[2025-02-14T06:47:09.113+0000] {logging_mixin.py:190} INFO - 데이터 샘플:
[2025-02-14T06:47:09.125+0000] {logging_mixin.py:190} INFO -    InvoiceNo StockCode  ... CustomerID         Country
0    536365    85123A  ...    17850.0  United Kingdom
1    536365     71053  ...    17850.0  United Kingdom
2    536365    84406B  ...    17850.0  United Kingdom
3    536365    84029G  ...    17850.0  United Kingdom
4    536365    84029E  ...    17850.0  United Kingdom

[5 rows x 8 columns]
[2025-02-14T06:47:09.125+0000] {logging_mixin.py:190} INFO - Data extracted successfully!
[2025-02-14T06:47:09.125+0000] {logging_mixin.py:190} INFO - Transforming data...
[2025-02-14T06:47:09.126+0000] {logging_mixin.py:190} INFO - 변환 전 컬럼: ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
[2025-02-14T06:47:09.376+0000] {logging_mixin.py:190} INFO - Data transformed successfully!
[2025-02-14T06:47:09.377+0000] {logging_mixin.py:190} INFO - Loading data...
[2025-02-14T06:47:28.619+0000] {logging_mixin.py:190} INFO - Data loaded successfully!
[2025-02-14T06:47:28.632+0000] {logging_mixin.py:190} INFO - ETL pipeline completed successfully!
[2025-02-14T06:47:28.672+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-02-14T06:47:28.697+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-14T06:47:28.697+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=etl_pipeline_dag, task_id=run_etl_pipeline, run_id=scheduled__2025-02-13T00:00:00+00:00, execution_date=20250213T000000, start_date=20250214T064502, end_date=20250214T064728
[2025-02-14T06:47:28.733+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-02-14T06:47:28.763+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-14T06:47:28.764+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
